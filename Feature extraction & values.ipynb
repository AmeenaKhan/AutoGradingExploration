{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from nltk.corpus import stopwords\n",
    "import textblob \n",
    "import enchant\n",
    "import nltk\n",
    "stemmer = nltk.stem.SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    df= pd.read_csv(filename)\n",
    "    df = df.set_index('essay_id')\n",
    "    df = df[['essay','rater1_domain1']]\n",
    "    stop = stopwords.words('english')\n",
    "    df['essay'] = df['essay'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    df['essay'] = df['essay'].apply(lambda x: ' '.join([stemmer.stem(word) for word in x.split() if '@' not in word]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>rater1_domain1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dear local newspaper, i think effect comput pe...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dear i believ use comput benefit us mani way l...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dear, more peopl use computers, everyon agre b...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dear local newspaper, i found mani expert say ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dear i know comput posit effect people. the co...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      essay  rater1_domain1\n",
       "essay_id                                                                   \n",
       "1         dear local newspaper, i think effect comput pe...             4.0\n",
       "2         dear i believ use comput benefit us mani way l...             5.0\n",
       "3         dear, more peopl use computers, everyon agre b...             4.0\n",
       "4         dear local newspaper, i found mani expert say ...             5.0\n",
       "5         dear i know comput posit effect people. the co...             4.0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_set_1 = get_data('essay_set_1.csv')\n",
    "essay_set_2 = get_data('essay_set_2.csv')\n",
    "essay_set_7 = get_data('essay_set_7.csv')\n",
    "essay_set_8 = get_data('essay_set_8.csv')\n",
    "essay_set_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "essay_set_1['vocab'] = 0\n",
    "essay_set_2['vocab'] = 0\n",
    "essay_set_7['vocab'] = 0\n",
    "essay_set_8['vocab'] = 0\n",
    "\n",
    "essay_set_1.loc[essay_set_1.rater1_domain1 >= 3, 'vocab'] = 1\n",
    "essay_set_1.loc[essay_set_1.rater1_domain1 >= 5, 'vocab'] = 2\n",
    "essay_set_1.drop('rater1_domain1',inplace=True,axis=1)\n",
    "\n",
    "essay_set_2.loc[essay_set_2.rater1_domain1 >= 3, 'vocab'] = 1\n",
    "essay_set_2.loc[essay_set_2.rater1_domain1 >= 5, 'vocab'] = 2\n",
    "essay_set_2.drop('rater1_domain1',inplace=True,axis=1)\n",
    "\n",
    "essay_set_7.loc[essay_set_7.rater1_domain1 >= 5, 'vocab'] = 1\n",
    "essay_set_7.loc[essay_set_7.rater1_domain1 >= 10, 'vocab'] = 2\n",
    "essay_set_7.drop('rater1_domain1',inplace=True,axis=1)\n",
    "\n",
    "essay_set_8.loc[essay_set_8.rater1_domain1 >= 11, 'vocab'] = 1\n",
    "essay_set_8.loc[essay_set_8.rater1_domain1 >= 21, 'vocab'] = 2\n",
    "essay_set_8.drop('rater1_domain1',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocab</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1783.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.330342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.513799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             vocab\n",
       "count  1783.000000\n",
       "mean      1.330342\n",
       "std       0.513799\n",
       "min       0.000000\n",
       "25%       1.000000\n",
       "50%       1.000000\n",
       "75%       2.000000\n",
       "max       2.000000"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essay_set_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay</th>\n",
       "      <th>vocab</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>essay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4145</th>\n",
       "      <td>freedom chose someth everi person have, type c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>there mani differ side comput problem, well it...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>i person dont think censorship book come i thi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3612</th>\n",
       "      <td>what library? a librari place go books, movies...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>books, music, movies, magazines, we'v pleasur ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      essay  vocab\n",
       "essay_id                                                          \n",
       "4145      freedom chose someth everi person have, type c...      1\n",
       "136       there mani differ side comput problem, well it...      1\n",
       "3491      i person dont think censorship book come i thi...      0\n",
       "3612      what library? a librari place go books, movies...      1\n",
       "3722      books, music, movies, magazines, we'v pleasur ...      2"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [essay_set_1, essay_set_2, essay_set_7, essay_set_8]\n",
    "df = pd.concat(frames)\n",
    "df = df.reindex(numpy.random.permutation(df.index))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "counts = count_vectorizer.fit_transform(df['essay'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer()),\n",
    "    ('classifier',  MultinomialNB()) ])\n",
    "\n",
    "pipeline.fit(df['essay'].values, df['vocab'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.664397549353\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>182</td>\n",
       "      <td>11</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1575</td>\n",
       "      <td>540</td>\n",
       "      <td>2115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>374</td>\n",
       "      <td>627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>925</td>\n",
       "      <td>2938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction  0     1    2   All\n",
       "Actual                        \n",
       "0           3   182   11   196\n",
       "1           0  1575  540  2115\n",
       "2           0   253  374   627\n",
       "All         3  2010  925  2938"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "train,test,tr_y,te_y = train_test_split(df['essay'],df['vocab'], test_size = 0.5)\n",
    "pipeline.fit(train, tr_y)\n",
    "predictions = pipeline.predict(test)\n",
    "vals = [0,1,2]\n",
    "y_actu = pd.Categorical(te_y, categories=vals)\n",
    "y_actu = pd.Series(y_actu,name=\"Actual\")\n",
    "y_pred = pd.Categorical(predictions, categories=vals)\n",
    "y_pred = pd.Series(y_pred,name=\"Prediction\")\n",
    "print('Accuracy Score:', accuracy_score(y_actu, y_pred))\n",
    "pd.crosstab(y_actu, y_pred,margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
