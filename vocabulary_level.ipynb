{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "from autocorrect import spell #import spell checker\n",
    "import numpy as np\n",
    "from textstat.textstat import textstat #import vocabulary level grader\n",
    "from sklearn.cross_validation import train_test_split #for training and testing split\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "import csv\n",
    "import numpy\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This code clean the essays\n",
    "\n",
    "## It removes:\n",
    "\n",
    "1. Stopwords\n",
    "2. Stemming\n",
    "3. puts everything in lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_Essay( raw_review ):\n",
    "    stemmer = nltk.stem.SnowballStemmer('english')\n",
    "    # Function to convert a raw review to a string of words\n",
    "    # The input is a single string (a raw movie review), and \n",
    "    # the output is a single string (a preprocessed movie review)\n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", raw_review) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [spell(stemmer.stem(w)) for w in words if not w in stops]   \n",
    "    # 6. Doing a spell corrector\n",
    "    # 7. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is for setting up the data only if CSV file not avaible\n",
    "df = pd.read_csv(\"train_all_sets.csv\", index_col=False)\n",
    "df.columns\n",
    "sets = [3,4,7,8,9]\n",
    "df=df.loc[df[\"EssaySet\"].isin(sets)]#we only keep essays for datasets of enligh subject\n",
    "df = df[['EssayText','Score1']] #keep on 2 cols\n",
    "df['EssayText'] = df['EssayText'].apply(lambda x: clean_Essay(x))#check cell above\n",
    "#this is to check if we have a null value\n",
    "df[df.isnull().any(axis=1)]\n",
    "#this is to drop NaN values\n",
    "df.dropna(axis=0,how='any', inplace=True)\n",
    "df.to_csv(\"English_cleaned.csv\",index=False)#save the file to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#if you just want to load the dataframe and see results then call this\n",
    "df = pd.read_csv(\"English_cleaned.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#this is a sample classifier based upon the cleaned english datasets\n",
    "def classifier(text):\n",
    "    pipeline = Pipeline([\n",
    "        ('vectorizer',  CountVectorizer()),\n",
    "        ('classifier',  MultinomialNB()) ])\n",
    "    pipeline.fit(df['EssayText'].values, df['Score1'].values)\n",
    "    return pipeline.predict(text)[0] # produce predicted score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#give vocabulary grade level\n",
    "def grade_assign(text):\n",
    "    print (textstat.automated_readability_index(text),textstat.flesch_kincaid_grade(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pipeline\n",
    "pipeline = Pipeline([\n",
    "        ('vectorizer',  CountVectorizer()),\n",
    "        ('tfidf_transformer',  TfidfTransformer()),\n",
    "        ('classifier',  RandomForestClassifier(n_estimators=100)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:375: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:375: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:375: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:375: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:375: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total emails classified: 9024\n",
      "Score: 0.56560984498\n",
      "Confusion matrix:\n",
      "[[2036  785  213]\n",
      " [ 788 2483  328]\n",
      " [ 244  843 1304]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:375: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    }
   ],
   "source": [
    "#resutls with confusion matrix using kfolds\n",
    "\n",
    "k_fold = KFold(n=len(df), n_folds=6)\n",
    "scores = []\n",
    "confusion = numpy.array([[0,0,0], [0,0,0], [0,0,0]])\n",
    "for train_indices, test_indices in k_fold:\n",
    "    train_text = df.iloc[train_indices]['EssayText'].values\n",
    "    train_y = df.iloc[train_indices]['Score1'].values\n",
    "    test_text = df.iloc[test_indices]['EssayText'].values\n",
    "    test_y = df.iloc[test_indices]['Score1'].values\n",
    "    pipeline.fit(train_text, train_y)\n",
    "    predictions = pipeline.predict(test_text)\n",
    "    confusion += confusion_matrix(test_y, predictions)\n",
    "    score = f1_score(test_y, predictions, labels=['0','1','2'],average='macro')\n",
    "    scores.append(score)\n",
    "print('Total emails classified:', len(df))\n",
    "print('Score:', sum(scores)/len(scores))\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 0.66703601108\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Prediction</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>402</td>\n",
       "      <td>166</td>\n",
       "      <td>46</td>\n",
       "      <td>614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>497</td>\n",
       "      <td>74</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52</td>\n",
       "      <td>135</td>\n",
       "      <td>305</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>582</td>\n",
       "      <td>798</td>\n",
       "      <td>425</td>\n",
       "      <td>1805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Prediction    0    1    2   All\n",
       "Actual                         \n",
       "0           402  166   46   614\n",
       "1           128  497   74   699\n",
       "2            52  135  305   492\n",
       "All         582  798  425  1805"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pretty print for table of confusion matrix with no kfolds\n",
    "train,test,tr_y,te_y = train_test_split(df['EssayText'],df['Score1'], test_size = 0.2)\n",
    "pipeline.fit(train, tr_y)\n",
    "predictions = pipeline.predict(test)\n",
    "vals = [0,1,2]\n",
    "y_actu = pd.Categorical(te_y, categories=vals)\n",
    "y_actu = pd.Series(y_actu,name=\"Actual\")\n",
    "y_pred = pd.Categorical(predictions, categories=vals)\n",
    "y_pred = pd.Series(y_pred,name=\"Prediction\")\n",
    "print('Accuracy Score:', accuracy_score(y_actu, y_pred))\n",
    "pd.crosstab(y_actu, y_pred,margins = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
